# Edge-preservingand-image-denoising-using-DNCNN

Below is a revised **README.md** with the neural-network diagram and its download link removed. Everything else is unchanged.

```markdown
# Lightweight Edge-Aware Image Super-Resolution  
*A residual CNN baseline with DIV2K, Canny + LoG edge loss, and minimal dependencies*

<div align="center">
  <img src="https://img.shields.io/badge/TF-2.x-blue?style=flat-square"/>
  <img src="https://img.shields.io/badge/Python-3.9%2B-yellow?style=flat-square"/>
  <img src="https://img.shields.io/badge/License-MIT-green?style=flat-square"/>
</div>

---

## âœ¨ Overview
This repository contains a concise yet powerful super-resolution (SR) model aimed at **research prototypes, education, and quick benchmarks**.

* **Residual CNN** (4 lightweight blocks, ~300 k params).  
* **Edge-aware training** â€“ combines _L1_ with a Canny + LoG edge loss to boost perceptual sharpness.  
* **Noise robustness** â€“ trains on Gaussian-noisy inputs so the network learns both de-noising and SR.  
* **Self-contained** â€“ one file, no custom C/CUDA ops.  
* **TensorFlow Datasets** â€“ pulls DIV2K automatically.

<p align="center">
  <img alt="Qualitative result" src="docs/example_grid.png" width="600">
  <br>
  <sup>Left â†’ noisy input &nbsp;&nbsp;|&nbsp;&nbsp; center â†’ network output &nbsp;&nbsp;|&nbsp;&nbsp; right â†’ clean ground-truth</sup>
</p>

---

## ğŸ§© Network Architecture

| Stage | Details | Output size |
|-------|---------|-------------|
| **Input** | RGB patch | 128 Ã— 128 Ã— 3 |
| **Residual Block Ã— 4** | Conv(3 Ã— 3, 64) â†’ BN â†’ ReLU â†’ _(optional Dropout)_ â†’ Conv(3 Ã— 3, 64) â†’ BN â†’ Add skip â†’ ReLU | 128 Ã— 128 Ã— 64 |
| **Final Conv** | Conv(3 Ã— 3, 3) + Sigmoid | 128 Ã— 128 Ã— 3 |
| **Output** | Super-resolved patch | 128 Ã— 128 Ã— 3 |

<details>
<summary>Why so small?</summary>

A four-block backbone is enough to demonstrate the **edge loss** and training loop without eating GPU memory or requiring long runtimes.  
Swap in more blocks or a deeper UNet if you need higher PSNR.
</details>

---

## ğŸ”§ Installation

```bash
git clone https://github.com/your-username/lightweight-sr.git
cd lightweight-sr
python -m venv .venv
source .venv/bin/activate        # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

**Dependencies**

| Package | Tested version |
|---------|----------------|
| `tensorflow` | 2.17 |
| `tensorflow-datasets` | 4.9 |
| `numpy` Â· `matplotlib` Â· `scikit-image` Â· `scipy` | latest |

> **Tip** â€“ Installing TensorFlow with GPU support is strongly recommended for >10 k iters.

---

## ğŸš€ Quickstart

Train a toy model on **40** DIV2K images for **1 epoch**:

```bash
python sr_edge.py --epochs 1 --num_samples 40 --batch_size 8
```

That finishes in a couple of minutes on a single GPU.  
After training, a qualitative demo window pops up automatically.

### CLI flags

| Flag | Default | Description |
|------|---------|-------------|
| `--epochs` | `5` | Training epochs |
| `--batch_size` | `8` | Mini-batch size |
| `--num_samples` | `200` | Number of DIV2K crops to load |
| `--sigma` | `0.05` | Gaussian Ïƒ for synthetic noise |

---

## ğŸ“š Code Walkthrough

```
sr_edge.py
â”‚
â”œâ”€â”€ load_div2k()      # tfds + resize + [0,1] float32
â”œâ”€â”€ add_gaussian_noise()
â”‚
â”œâ”€â”€ edge_map()        # Canny + Laplacian-of-Gaussian
â”œâ”€â”€ edge_loss()       # |edge(gt) âˆ’ edge(pred)|
â”‚
â”œâ”€â”€ residual_block()  # Conv-BN-ReLU-(Dropout)-Conv-BN + skip
â”œâ”€â”€ build_sr_model()  # 4 residual blocks + final conv
â”‚
â”œâ”€â”€ SRDataGenerator   # tf.keras.utils.Sequence wrapper
â”œâ”€â”€ train_sr_model()  # compile(), fit()
â””â”€â”€ show_results()    # matplotlib grid
```

---

## ğŸ“ Loss Function Details

| Component | Expression | Weight |
|-----------|------------|--------|
| **Pixel L1** | `MAE(y_true, y_pred)` | **0.8** |
| **Edge** | `mean(|edge(y_true) âˆ’ edge(y_pred)|)` | **0.2** |

Where  

```
edge(x) = max( Canny(x,Ïƒ=1),
               1{ LoG(x,Ïƒ=1) > 0 } )
```

The edge term encourages crisp structures that pure *L1* often blurs.

---

## ğŸ” Evaluation

Run **PSNR** on the held-out validation set:

```python
from sr_edge import load_div2k, add_gaussian_noise, psnr

# Load val images
val = load_div2k(num_samples=100)
lr  = add_gaussian_noise(val)

psnr_vals = psnr(val, model.predict(lr))
print("Mean PSNR:", psnr_vals.numpy())
```

Add SSIM, LPIPS, or your favourite perceptual metric as needed.

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ sr_edge.py
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ docs/
    â””â”€â”€ example_grid.png
```

> Keep heavy sample outputs under `docs/` so they render in the GitHub UI but stay out of your Python package path.

---

## ğŸ—ºï¸ Roadmap / TODO

- [ ] Replace Gaussian noise with authentic low-resolution down-sampling.  
- [ ] WandB / TensorBoard integration.  
- [ ] Quantize for mobile deployment (TFLite).  
- [ ] Add UNet-SRGAN variant.

---

## ğŸ“œ License

This project is released under the **MIT License** â€“ see `LICENSE` for details.  
DIV2K is distributed by the original authors under a separate **Creative Commons BY-NC-SA 4.0** license.

---

## ğŸ™ Acknowledgements

* [DIV2K](https://data.vision.ee.ethz.ch/cvl/DIV2K/) dataset  
* Kaiming He *et al.* â€“ **â€œDeep Residual Learning for Image Recognitionâ€**  
* skimage team for high-quality image processing utilities.

---

## âœï¸ Citation

If you build on this repo, feel free to cite it as:

```text
@misc{lightweightSR2025,
  author       = {Your Name},
  title        = {Lightweight Edge-Aware Image Super-Resolution},
  year         = 2025,
  howpublished = {\url{https://github.com/your-username/lightweight-sr}}
}
```

Happy super-resolving! ğŸš€
```

---
